{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL Assignment 1: Imitation Learning\n",
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "\n",
    "home_work_root=os.path.abspath('..')\n",
    "\n",
    "\n",
    "def collect_expert_data(env_name, max_timesteps=None, num_rollouts=20, render=False):\n",
    "    from load_policy import load_policy\n",
    "    policy_fn = load_policy(os.path.join(home_work_root, 'experts', env_name+'.pkl'))\n",
    "    \n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "        env = gym.make(env_name)\n",
    "        max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        for i in range(num_rollouts):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps % 10 == 0:\n",
    "                    print(\"\\rIter{0}/{1}: {2}/{3}\".format(i+1, num_rollouts, steps+1, max_steps), end='')\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "        print('. done')\n",
    "\n",
    "        #print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "    return {'observation': observations, 'actions': actions}\n",
    "\n",
    "def test_policy(env_name, policy, max_timesteps=None, num_rollouts=20, render=False):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_names=['Humanoid-v1',]\n",
    "expert_data={env: collect_expert_data(env, num_rollouts=200) for env in env_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models  import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def build_model(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    assert len(env.action_space.shape) == 1\n",
    "    #actions = keras.placeholder(shape=env.action_space.shape, dtype=tf.float32)\n",
    "    #obs = tf.placeholder(shape=env.observation_space.shape, dtype=tf.float32)\n",
    "    \n",
    "    from functools import reduce\n",
    "    n_obs = reduce((lambda x, y: x * y), env.observation_space.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    if len(env.observation_space.shape) > 1:\n",
    "        model.add(Flatten(input_shape=env.observation_space.shape))\n",
    "    model.add(BatchNormalization(input_shape=(n_obs,)))\n",
    "    #model.add(Dense(n_obs*8, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_obs*4, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    #model.add(Dense(n_obs, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(env.action_space.shape[0]*2, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(env.action_space.shape[0], activation='linear'))\n",
    "    \n",
    "    return model, env\n",
    "\n",
    "def train_model(model, env, x, y):\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(x, y, batch_size=128, epochs=20, verbose=2)\n",
    "\n",
    "for env_name in expert_data:\n",
    "    observations= expert_data[env_name]['observation']\n",
    "    actions = expert_data[env_name]['actions']\n",
    "    #obs_, actions_, cost, env = build_model(env_name)\n",
    "    #train_model(policy, env, feed_dict={obs_: obs, actions_: actions})\n",
    "    model, env = build_model(env_name)\n",
    "    train_model(model, env, x=np.array(observations), y=np.squeeze(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(env, model,max_timesteps=None, num_rollouts=20, render=False):\n",
    "    max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(num_rollouts):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            print(obs[np.newaxis].shape)\n",
    "            action = model.predict(obs[np.newaxis])\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            if steps % 10 == 0:\n",
    "                print(\"\\rIter{0}/{1}: {2}/{3}\".format(i+1, num_rollouts, steps+1, max_steps), end='')\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "    env.render(close=True)\n",
    "    print('. done')\n",
    "\n",
    "    #print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return', np.std(returns))\n",
    "\n",
    "test_model(env, model, num_rollouts=30, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
