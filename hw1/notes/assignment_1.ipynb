{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL Assignment 1: Imitation Learning\n",
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "\n",
    "home_work_root=os.path.abspath('..')\n",
    "\n",
    "\n",
    "def collect_expert_data(env_name, max_timesteps=None, num_rollouts=20, render=False):\n",
    "    from load_policy import load_policy\n",
    "    policy_fn = load_policy(os.path.join(home_work_root, 'experts', env_name+'.pkl'))\n",
    "    \n",
    "    with tf.Session():\n",
    "        tf_util.initialize()\n",
    "        env = gym.make(env_name)\n",
    "        max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        for i in range(num_rollouts):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps % 10 == 0:\n",
    "                    print(\"\\rIter{0}/{1}: {2}/{3}\".format(i+1, num_rollouts, steps+1, max_steps), end='')\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            returns.append(totalr)\n",
    "        print('. done')\n",
    "\n",
    "        #print('returns', returns)\n",
    "        print('mean return', np.mean(returns))\n",
    "        print('std of return', np.std(returns))\n",
    "    return {'observation': observations, 'actions': actions}\n",
    "\n",
    "def test_policy(env_name, policy, max_timesteps=None, num_rollouts=20, render=False):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-06 09:32:33,796] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter100/100: 1001/1000. done\n",
      "mean return 4783.75190287\n",
      "std of return 288.136414554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-06 09:34:40,411] Making new env: Reacher-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter100/100: 51/50. done\n",
      "mean return -3.77229226691\n",
      "std of return 1.78029449976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-06 09:34:48,156] Making new env: Hopper-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter100/100: 1001/1000. done\n",
      "mean return 3778.26273809\n",
      "std of return 3.45802476193\n"
     ]
    }
   ],
   "source": [
    "env_names=['Ant-v1', 'Reacher-v1', 'Hopper-v1']\n",
    "expert_data={env: collect_expert_data(env, num_rollouts=100) for env in env_names}\n",
    "import pickle\n",
    "with open('expert_data.pkl', 'wb') as f:\n",
    "    pickle.dump(expert_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "expert_data={}\n",
    "with open('expert_data.pkl', 'rb') as f:\n",
    "    loaded=pickle.load(f)\n",
    "    if loaded:\n",
    "        expert_data.update(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models  import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def build_model(env_name):\n",
    "    env = gym.make(env_name)\n",
    "    assert len(env.action_space.shape) == 1\n",
    "    #actions = keras.placeholder(shape=env.action_space.shape, dtype=tf.float32)\n",
    "    #obs = tf.placeholder(shape=env.observation_space.shape, dtype=tf.float32)\n",
    "    \n",
    "    from functools import reduce\n",
    "    n_obs = reduce((lambda x, y: x * y), env.observation_space.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    if len(env.observation_space.shape) > 1:\n",
    "        model.add(Flatten(input_shape=env.observation_space.shape))\n",
    "    model.add(BatchNormalization(input_shape=(n_obs,)))\n",
    "    model.add(Dense(n_obs*8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_obs*4, activation='relu'))\n",
    "    #model.add(Dense(env.action_space.shape[0]*4, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(n_obs*4, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(n_obs, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(env.action_space.shape[0]*2, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(env.action_space.shape[0], activation='linear'))\n",
    "    \n",
    "    return model, env\n",
    "\n",
    "def train_model(model, env, x, y, batch_size=20, epochs=20):\n",
    "    print(model.summary())\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    from keras.callbacks import TensorBoard\n",
    "    from datetime import datetime\n",
    "    tensorboard=TensorBoard(log_dir='./logs/'+env.spec.id+'_'+datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n",
    "                            histogram_freq=0, write_graph=True, write_images=True)\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=2,\n",
    "              callbacks=[tensorboard])\n",
    "\n",
    "def imitation(env_name, batch_size=20, epochs=20):\n",
    "    observations= expert_data[env_name]['observation']\n",
    "    actions = expert_data[env_name]['actions']\n",
    "    #obs_, actions_, cost, env = build_model(env_name)\n",
    "    #train_model(policy, env, feed_dict={obs_: obs, actions_: actions})\n",
    "    model, env = build_model(env_name)\n",
    "    train_model(model, env, x=np.array(observations), y=np.squeeze(actions), batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_model(env_name, model,max_timesteps=None, num_rollouts=20, render=False):\n",
    "    env = gym.make(env_name)\n",
    "    max_steps = max_timesteps or env.spec.timestep_limit\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(num_rollouts):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model.predict(obs[np.newaxis])\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            if steps % 10 == 0:\n",
    "                print(\"\\rIter{0}/{1}: {2}/{3}\".format(i+1, num_rollouts, steps+1, max_steps), end='')\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "    if render:\n",
    "        env.render(close=True)\n",
    "    print('. done')\n",
    "\n",
    "    #print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return', np.std(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-06 17:01:44,476] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_19 (Batc (None, 111)               444       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 888)               99456     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 888)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 444)               394716    \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 444)               197580    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 111)               49395     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 111)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 16)                1792      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 743,519\n",
      "Trainable params: 743,297\n",
      "Non-trainable params: 222\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "10s - loss: 0.0411 - acc: 0.4928\n",
      "Epoch 2/30\n",
      "10s - loss: 0.0230 - acc: 0.6645\n",
      "Epoch 3/30\n",
      "10s - loss: 0.0196 - acc: 0.6935\n",
      "Epoch 4/30\n",
      "10s - loss: 0.0175 - acc: 0.7118\n",
      "Epoch 5/30\n",
      "10s - loss: 0.0160 - acc: 0.7229\n",
      "Epoch 6/30\n",
      "10s - loss: 0.0150 - acc: 0.7355\n",
      "Epoch 7/30\n",
      "10s - loss: 0.0141 - acc: 0.7427\n",
      "Epoch 8/30\n",
      "10s - loss: 0.0134 - acc: 0.7522\n",
      "Epoch 9/30\n",
      "10s - loss: 0.0129 - acc: 0.7559\n",
      "Epoch 10/30\n",
      "10s - loss: 0.0124 - acc: 0.7614\n",
      "Epoch 11/30\n",
      "10s - loss: 0.0121 - acc: 0.7647\n",
      "Epoch 12/30\n",
      "10s - loss: 0.0116 - acc: 0.7677\n",
      "Epoch 13/30\n",
      "10s - loss: 0.0114 - acc: 0.7707\n",
      "Epoch 14/30\n",
      "10s - loss: 0.0111 - acc: 0.7737\n",
      "Epoch 15/30\n",
      "10s - loss: 0.0109 - acc: 0.7753\n",
      "Epoch 16/30\n",
      "11s - loss: 0.0106 - acc: 0.7769\n",
      "Epoch 17/30\n",
      "10s - loss: 0.0105 - acc: 0.7789\n",
      "Epoch 18/30\n",
      "10s - loss: 0.0103 - acc: 0.7815\n",
      "Epoch 19/30\n",
      "10s - loss: 0.0101 - acc: 0.7826\n",
      "Epoch 20/30\n",
      "10s - loss: 0.0099 - acc: 0.7876\n",
      "Epoch 21/30\n",
      "10s - loss: 0.0098 - acc: 0.7845\n",
      "Epoch 22/30\n",
      "10s - loss: 0.0096 - acc: 0.7888\n",
      "Epoch 23/30\n",
      "10s - loss: 0.0096 - acc: 0.7893\n",
      "Epoch 24/30\n",
      "10s - loss: 0.0094 - acc: 0.7916\n",
      "Epoch 25/30\n",
      "10s - loss: 0.0093 - acc: 0.7912\n",
      "Epoch 26/30\n",
      "10s - loss: 0.0093 - acc: 0.7936\n",
      "Epoch 27/30\n",
      "10s - loss: 0.0091 - acc: 0.7942\n",
      "Epoch 28/30\n",
      "10s - loss: 0.0090 - acc: 0.7946\n",
      "Epoch 29/30\n",
      "10s - loss: 0.0089 - acc: 0.7976\n",
      "Epoch 30/30\n",
      "10s - loss: 0.0088 - acc: 0.7980\n"
     ]
    }
   ],
   "source": [
    "model = imitation('Ant-v1', batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-06 13:35:02,827] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter20/20: 1001/1000. done\n",
      "mean return 3344.86546998\n",
      "std of return 2076.13817039\n"
     ]
    }
   ],
   "source": [
    "test_model('Ant-v1', model, num_rollouts=20, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ant-v1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
